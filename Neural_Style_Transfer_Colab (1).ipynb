{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udfa8 Neural Style Transfer with VGG19 (Google Colab Ready)\n", "\n", "This notebook uses TensorFlow and a pre-trained VGG19 model to apply the artistic style of one image (e.g., Van Gogh's *Starry Night*) to the content of another image (e.g., Golden Gate Bridge photo)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 STEP 1: Install required libraries\n", "!pip install tensorflow matplotlib --quiet"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 STEP 2: Import libraries\n", "import tensorflow as tf\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import PIL.Image\n", "import time\n", "from tensorflow.keras.applications import vgg19\n", "from tensorflow.keras.preprocessing import image as kp_image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 STEP 3: Helper functions\n", "def load_img(path_to_img):\n", "    max_dim = 512\n", "    img = PIL.Image.open(path_to_img)\n", "    long = max(img.size)\n", "    scale = max_dim / long\n", "    img = img.resize((round(img.size[0]*scale), round(img.size[1]*scale)), PIL.Image.ANTIALIAS)\n", "    img = kp_image.img_to_array(img)\n", "    img = np.expand_dims(img, axis=0)\n", "    return tf.image.convert_image_dtype(img, tf.float32)\n", "\n", "def deprocess_img(processed_img):\n", "    x = processed_img.copy()\n", "    x = x.reshape((x.shape[1], x.shape[2], 3))\n", "    x = np.clip(x, 0, 1)\n", "    return x\n", "\n", "def show_img(img, title=None):\n", "    plt.imshow(deprocess_img(img))\n", "    if title:\n", "        plt.title(title)\n", "    plt.axis('off')\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 STEP 4: Download content and style images\n", "!wget https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg -O content.jpg\n", "!wget https://upload.wikimedia.org/wikipedia/commons/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg -O style.jpg\n", "\n", "content_path = \"content.jpg\"\n", "style_path = \"style.jpg\"\n", "\n", "content_image = load_img(content_path)\n", "style_image = load_img(style_path)\n", "\n", "show_img(content_image, \"Content Image\")\n", "show_img(style_image, \"Style Image\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 STEP 5: Define VGG19 layers for style/content\n", "content_layers = ['block5_conv2']\n", "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n", "\n", "num_content_layers = len(content_layers)\n", "num_style_layers = len(style_layers)\n", "\n", "def get_model():\n", "    vgg = vgg19.VGG19(include_top=False, weights='imagenet')\n", "    vgg.trainable = False\n", "    style_outputs = [vgg.get_layer(name).output for name in style_layers]\n", "    content_outputs = [vgg.get_layer(name).output for name in content_layers]\n", "    model_outputs = style_outputs + content_outputs\n", "    return tf.keras.Model(vgg.input, model_outputs)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 STEP 6: Feature extraction & loss\n", "def get_feature_representations(model, content_img, style_img):\n", "    content_img = content_img * 255.0\n", "    style_img = style_img * 255.0\n", "\n", "    preprocessed_content = vgg19.preprocess_input(content_img)\n", "    preprocessed_style = vgg19.preprocess_input(style_img)\n", "\n", "    style_outputs = model(preprocessed_style)\n", "    content_outputs = model(preprocessed_content)\n", "\n", "    style_features = [style_layer for style_layer in style_outputs[:num_style_layers]]\n", "    content_features = [content_layer for content_layer in content_outputs[num_style_layers:]]\n", "\n", "    return style_features, content_features\n", "\n", "def gram_matrix(input_tensor):\n", "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n", "    input_shape = tf.shape(input_tensor)\n", "    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n", "    return result / num_locations\n", "\n", "def compute_loss(model, loss_weights, init_image, gram_style_features, content_features):\n", "    model_outputs = model(init_image)\n", "\n", "    style_output_features = model_outputs[:num_style_layers]\n", "    content_output_features = model_outputs[num_style_layers:]\n", "\n", "    style_score = 0\n", "    content_score = 0\n", "\n", "    weight_style, weight_content = loss_weights\n", "\n", "    for target_style, comb_style in zip(gram_style_features, style_output_features):\n", "        style_score += tf.reduce_mean((gram_matrix(comb_style) - target_style) ** 2)\n", "\n", "    for target_content, comb_content in zip(content_features, content_output_features):\n", "        content_score += tf.reduce_mean((comb_content - target_content) ** 2)\n", "\n", "    style_score *= weight_style / num_style_layers\n", "    content_score *= weight_content / num_content_layers\n", "\n", "    loss = style_score + content_score\n", "    return loss\n", "\n", "@tf.function()\n", "def compute_grads(cfg):\n", "    with tf.GradientTape() as tape:\n", "        all_loss = compute_loss(**cfg)\n", "    total_loss = all_loss\n", "    return tape.gradient(total_loss, cfg['init_image']), total_loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 STEP 7: Run style transfer\n", "def run_style_transfer(content_path, style_path, num_iterations=250, content_weight=1e3, style_weight=1e-2):\n", "    model = get_model()\n", "    for layer in model.layers:\n", "        layer.trainable = False\n", "\n", "    content_image = load_img(content_path)\n", "    style_image = load_img(style_path)\n", "\n", "    style_features, content_features = get_feature_representations(model, content_image, style_image)\n", "    gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]\n", "\n", "    init_image = tf.Variable(content_image, dtype=tf.float32)\n", "    opt = tf.optimizers.Adam(learning_rate=5.0)\n", "\n", "    best_loss, best_img = float('inf'), None\n", "\n", "    loss_weights = (style_weight, content_weight)\n", "    cfg = {\n", "        'model': model,\n", "        'loss_weights': loss_weights,\n", "        'init_image': init_image,\n", "        'gram_style_features': gram_style_features,\n", "        'content_features': content_features\n", "    }\n", "\n", "    for i in range(num_iterations):\n", "        grads, loss = compute_grads(cfg)\n", "        opt.apply_gradients([(grads, init_image)])\n", "        clipped = tf.clip_by_value(init_image, 0.0, 1.0)\n", "        init_image.assign(clipped)\n", "\n", "        if loss < best_loss:\n", "            best_loss = loss\n", "            best_img = deprocess_img(init_image.numpy())\n", "\n", "        if i % 50 == 0:\n", "            print(f\"Iteration {i}, Loss: {loss}\")\n", "\n", "    return best_img\n", "\n", "stylized_img = run_style_transfer(content_path, style_path)\n", "plt.figure(figsize=(10,10))\n", "plt.imshow(stylized_img)\n", "plt.title(\"\ud83c\udfa8 Stylized Image\")\n", "plt.axis('off')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 4}